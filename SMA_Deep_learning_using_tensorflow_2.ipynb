{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMA_Deep_learning using tensorflow-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnEIXLibb/6BswZx/PNEgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erkamalkumar/gate-2019/blob/master/SMA_Deep_learning_using_tensorflow_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRuOMXckDYkl"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import datasets, layers, models, preprocessing\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "max_len = 200\r\n",
        "n_words = 10000\r\n",
        "dim_embedding = 256\r\n",
        "EPOCHS = 20\r\n",
        "BATCH_SIZE = 500\r\n",
        "def load_data():\r\n",
        "        # Load data.\r\n",
        "        (X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\r\n",
        "        # Pad sequences with max_len.\r\n",
        "        X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\r\n",
        "        X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\r\n",
        "        return (X_train, y_train), (X_test, y_test)\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKSoiEgnDiTi"
      },
      "source": [
        "def build_model():\r\n",
        "    model = models.Sequential()\r\n",
        "    # Input: - eEmbedding Layer.\r\n",
        "    # The model will take as input an integer matrix of size (batch,     # input_length).\r\n",
        "    # The model will output dimension (input_length, dim_embedding).\r\n",
        "    # The largest integer in the input should be no larger\r\n",
        "    # than n_words (vocabulary size).\r\n",
        "    model.add(layers.Embedding(n_words, dim_embedding, input_length=max_len))\r\n",
        "    model.add(layers.Dropout(0.3))\r\n",
        "    # Takes the maximum value of either feature vector from each of     # the n_words features.\r\n",
        "    model.add(layers.GlobalMaxPooling1D())\r\n",
        "    model.add(layers.Dense(128, activation='relu'))\r\n",
        "    model.add(layers.Dropout(0.5))\r\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "    return model\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQhxuliNFDwC",
        "outputId": "fea4ca02-e12d-40ba-c225-e9a9102d394c"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_data()\r\n",
        "model = build_model()\r\n",
        "model.summary()\r\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\r\n",
        " metrics = [\"accuracy\"]\r\n",
        ")\r\n",
        "score = model.fit(X_train, y_train,\r\n",
        " epochs = EPOCHS,\r\n",
        " batch_size = BATCH_SIZE,\r\n",
        " validation_data = (X_test, y_test)\r\n",
        ")\r\n",
        "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\r\n",
        "print(\"\\nTest score:\", score[0])\r\n",
        "print('Test accuracy:', score[1])\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 256)          2560000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200, 256)          0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,593,025\n",
            "Trainable params: 2,593,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 28s 546ms/step - loss: 0.6858 - accuracy: 0.5606 - val_loss: 0.6294 - val_accuracy: 0.8326\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 27s 538ms/step - loss: 0.5323 - accuracy: 0.8290 - val_loss: 0.3590 - val_accuracy: 0.8600\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 27s 541ms/step - loss: 0.2922 - accuracy: 0.8810 - val_loss: 0.3051 - val_accuracy: 0.8733\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 27s 542ms/step - loss: 0.2239 - accuracy: 0.9156 - val_loss: 0.2948 - val_accuracy: 0.8755\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 27s 541ms/step - loss: 0.1793 - accuracy: 0.9337 - val_loss: 0.2893 - val_accuracy: 0.8768\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 27s 541ms/step - loss: 0.1355 - accuracy: 0.9553 - val_loss: 0.2950 - val_accuracy: 0.8740\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 0.1035 - accuracy: 0.9684 - val_loss: 0.3049 - val_accuracy: 0.8707\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 27s 543ms/step - loss: 0.0791 - accuracy: 0.9794 - val_loss: 0.3210 - val_accuracy: 0.8652\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 27s 541ms/step - loss: 0.0598 - accuracy: 0.9843 - val_loss: 0.3365 - val_accuracy: 0.8634\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 27s 542ms/step - loss: 0.0481 - accuracy: 0.9902 - val_loss: 0.3537 - val_accuracy: 0.8602\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 27s 543ms/step - loss: 0.0323 - accuracy: 0.9932 - val_loss: 0.3707 - val_accuracy: 0.8580\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 27s 546ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 0.3880 - val_accuracy: 0.8560\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 27s 541ms/step - loss: 0.0214 - accuracy: 0.9958 - val_loss: 0.4086 - val_accuracy: 0.8544\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 27s 542ms/step - loss: 0.0162 - accuracy: 0.9973 - val_loss: 0.4204 - val_accuracy: 0.8540\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 27s 541ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.4389 - val_accuracy: 0.8520\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 0.0108 - accuracy: 0.9981 - val_loss: 0.4521 - val_accuracy: 0.8508\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.4604 - val_accuracy: 0.8508\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.4780 - val_accuracy: 0.8515\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 27s 543ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.4838 - val_accuracy: 0.8513\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.5043 - val_accuracy: 0.8494\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 0.5043 - accuracy: 0.8494\n",
            "\n",
            "Test score: 0.5042540431022644\n",
            "Test accuracy: 0.849399983882904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MxQ40SJFDpV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}